<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Colyn&#39;s Blog</title>
  
  <subtitle>Just make it! | Hi, I&#39;m Colyn</subtitle>
  <link href="https://blog.inetgeek.cn/atom.xml" rel="self"/>
  
  <link href="https://blog.inetgeek.cn/"/>
  <updated>2023-03-12T19:01:49.000Z</updated>
  <id>https://blog.inetgeek.cn/</id>
  
  <author>
    <name>Colyn</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【爬虫 | Python】解决‘Requests Max Retries Exceeded With Url‘报错的问题</title>
    <link href="https://blog.inetgeek.cn/2023/03/12/%E3%80%90%E7%88%AC%E8%99%AB%20|%20Python%E3%80%91%E8%A7%A3%E5%86%B3%E2%80%98Requests%20Max%20Retries%20Exceeded%20With%20Url%E2%80%98%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>https://blog.inetgeek.cn/2023/03/12/%E3%80%90%E7%88%AC%E8%99%AB%20|%20Python%E3%80%91%E8%A7%A3%E5%86%B3%E2%80%98Requests%20Max%20Retries%20Exceeded%20With%20Url%E2%80%98%E6%8A%A5%E9%94%99%E7%9A%84%E9%97%AE%E9%A2%98/</id>
    <published>2023-03-12T18:08:47.000Z</published>
    <updated>2023-03-12T19:01:49.000Z</updated>
    
    <content type="html"><![CDATA[<p><ul class="markdownIt-TOC"><li><a href="#%E4%B8%80-%E6%99%AE%E9%81%8D%E6%96%B9%E6%A1%88">一、普遍方案</a></li><li><a href="#%E7%BB%86%E8%87%B4%E6%96%B9%E6%A1%88">细致方案</a><ul><li><a href="#%E4%B8%80-%E9%97%AE%E9%A2%98%E9%87%8D%E8%BF%B0">一、问题重述</a><ul><li><a href="#1%E9%94%99%E8%AF%AF%E7%9A%84-url">1.错误的 URL</a></li><li><a href="#2%E6%9C%AA%E8%83%BD%E9%AA%8C%E8%AF%81-ssl-%E8%AF%81%E4%B9%A6">2.未能验证 SSL 证书</a></li><li><a href="#3%E7%BD%91%E7%BB%9C%E4%B8%8D%E7%A8%B3%E5%AE%9A">3.网络不稳定</a></li><li><a href="#4%E5%8F%91%E9%80%81%E5%A4%AA%E5%A4%9A%E8%AF%B7%E6%B1%82%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%87%E8%BD%BD">4.发送太多请求/服务器过载</a></li></ul></li><li><a href="#%E4%BA%8C-%E5%BA%94%E5%AF%B9%E6%96%B9%E6%A1%88">二、应对方案</a><ul><li><a href="#1%E6%96%B9%E6%A1%88%E4%B8%80%E4%BB%94%E7%BB%86%E6%A3%80%E6%9F%A5-url">1.方案一：仔细检查 URL</a></li><li><a href="#2%E6%96%B9%E6%A1%88%E4%BA%8C%E8%A7%A3%E5%86%B3sslerror">2.方案二：解决SSLError</a></li><li><a href="#3%E6%96%B9%E6%A1%88%E4%B8%89%E8%A7%A3%E5%86%B3%E7%BD%91%E7%BB%9C%E4%B8%8D%E7%A8%B3%E5%AE%9A%E7%9A%84%E9%97%AE%E9%A2%98">3.方案三：解决网络不稳定的问题</a><ul><li><a href="#%E6%96%B9%E6%A1%88a">方案A</a></li><li><a href="#%E6%96%B9%E6%A1%88b">方案B</a></li></ul></li><li><a href="#4%E6%96%B9%E6%A1%88%E5%9B%9B%E8%B6%85%E6%97%B6%E5%A4%84%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AF%B7%E6%B1%82">4.方案四：超时处理服务器请求</a></li></ul></li></ul></li></ul></p><h1 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h1><p>我们在写爬虫的时候，经常会遇到这样的报错信息：</p><blockquote><p>HTTPConnectionPool(host=‘<a href="http://xxx.xxx.com">xxx.xxx.com</a>’, port=443): Max retries exceeded with url: /api/v2/oauth (Caused by NewConnectionError(‘&lt;urllib3.connection.HTTPConnection object at 0x7fac5953ab70&gt;: Failed to establish a new connection: [Errno 110] Connection timed out’))</p></blockquote><p>这里有2个重要的信息点，分别是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTPConnectionPool(host=<span class="string">&#x27;xxx.xxx.com&#x27;</span>, port=<span class="number">443</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Max retries exceeded <span class="keyword">with</span> url:xxx (Caused by NewConnectionError(<span class="string">&#x27;&lt;urllib3.connection.HTTPConnection object at 0xxxxx)</span></span><br></pre></td></tr></table></figure><hr /><h1 id="解决方案"><a class="markdownIt-Anchor" href="#解决方案"></a> 解决方案</h1><hr /><h2 id="一-普遍方案"><a class="markdownIt-Anchor" href="#一-普遍方案"></a> 一、普遍方案</h2><p><strong>针对上述的问题，目前网上给出3种解决方案</strong>：</p><p>1.在Headers里添加<code>Connection</code>参数，使其为<code>close</code>，因为默认为<code>keep-alive</code>。</p><blockquote><p>因为requests使用的http连接池在发出request后会继续保持connection处于活跃状态，而http线程池里的的线程数是有限的。当多次request后，随机使用完了线程池里的session，因此为避免此问题需要设置connection为close来断连。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;close&#x27;</span> <span class="comment"># 设置为关闭长连接</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.使用<code>requests.close()</code>来关闭连接。</p><blockquote><p>使用<code>self.close()</code>主动断开宇服务器的连接。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">req = requests.get(url=<span class="string">&#x27;xxx&#x27;</span>, headers=<span class="string">&#x27;xxx&#x27;</span>, data=<span class="string">&#x27;xxx)</span></span><br><span class="line"><span class="string">req.close()    # 关闭连接</span></span><br></pre></td></tr></table></figure><p>3.使用<code>request.session（）</code>的请求方式。</p><blockquote><p>创建<code>session</code>，然后主动断开。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = requests.session()</span><br><span class="line">s.keep_alive = <span class="literal">False</span>  <span class="comment"># 关闭多余连接</span></span><br><span class="line">s.get(url=<span class="string">&#x27;xxx&#x27;</span>, headers=<span class="string">&#x27;xxx&#x27;</span>, data=<span class="string">&#x27;xxx)</span></span><br></pre></td></tr></table></figure><p>上面的3种方案也许能解决问题，但是经过尝试，<strong>并非所有情况都能有效解决问题</strong>。下面给出更加全面和细致的解决方案。</p><hr /><h2 id="细致方案"><a class="markdownIt-Anchor" href="#细致方案"></a> 细致方案</h2><blockquote><p>俗话说，具体问题具体分析。“因地制宜”才能真正解决所遇到的问题。</p></blockquote><p>当请求库无法成功将请求发送到发出的站点时，就会发生错误。发生这种情况是因为不同的原因。这是常见的。其中可能存在如下的问题所致：</p><p>1.错误的 URL （<a href="#1.方案一：仔细检查 URL">解决方案 1</a> ）<br />2.未能验证 SSL 证书（<a href="#2.方案二：解决SSLError">解决方案 2</a>）<br />3.使用没有或不稳定的互联网连接的请求（<a href="#3.方案三：解决网络不稳定的问题">解决方案 3</a>）<br />4.发送太多请求或服务器太忙（<a href="#4.方案四：超时处理服务器请求">解决方案 4</a>）</p><hr /><h3 id="一-问题重述"><a class="markdownIt-Anchor" href="#一-问题重述"></a> 一、问题重述</h3><h4 id="1错误的-url"><a class="markdownIt-Anchor" href="#1错误的-url"></a> 1.错误的 URL</h4><p>发生这种错误的其中一种可能的原因是你输入了错误的URL，导致request请求不到或超时。例如：</p><p>1.你把<code>com</code>写成了<code>con</code>，因此需要认真检查URL是否正确。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 错误的URL，应为https://www.github.com</span></span><br><span class="line">host = <span class="string">&#x27;https://www.github.con&#x27;</span> </span><br><span class="line">res = requests.get(url=host)</span><br><span class="line"><span class="built_in">print</span>(res) <span class="comment"># 报错</span></span><br></pre></td></tr></table></figure><p>2.你所调用的URL已失效或不存在，例如某个API已经失效或不存在，因此会发生此问题，可以使用浏览器检验一下该URL的有效性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 不存在的URL或已失效的URL</span></span><br><span class="line">host = <span class="string">&#x27;https://www.github.com/api/baidu&#x27;</span> </span><br><span class="line">res = requests.get(url=host)</span><br><span class="line"><span class="built_in">print</span>(res) <span class="comment"># 报错</span></span><br></pre></td></tr></table></figure><p>上述问题输出：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.exceptions.ConnectionError: <span class="constructor">HTTPSConnectionPool(<span class="params">host</span>=&#x27;<span class="params">www</span>.<span class="params">github</span>.<span class="params">coxxx</span>&#x27;, <span class="params">port</span>=443)</span>: Max retries exceeded <span class="keyword">with</span> url:<span class="operator"> / </span>(Caused by <span class="constructor">NewConnectionError(&#x27;&lt;<span class="params">urllib3</span>.<span class="params">connection</span>.VerifiedHTTPSConnection <span class="params">object</span> <span class="params">at</span> 0x7fd5b5d33100&gt;: Failed <span class="params">to</span> <span class="params">establish</span> <span class="params">a</span> <span class="params">new</span> <span class="params">connection</span>: [Errno 111] Connection <span class="params">refused</span>&#x27;)</span>)</span><br></pre></td></tr></table></figure><blockquote><p>可以观察到报错信息的最后部分是<code>Connection refused</code>。</p></blockquote><h4 id="2未能验证-ssl-证书"><a class="markdownIt-Anchor" href="#2未能验证-ssl-证书"></a> 2.未能验证 SSL 证书</h4><p>默认情况下，请求库实施 SSL 证书验证以确保您建立安全连接。<strong>如果无法验证证书</strong>，您最终会遇到如下错误：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.exceptions.ConnectionError: <span class="constructor">HTTPSConnectionPool(<span class="params">host</span>=&#x27;<span class="params">www</span>.<span class="params">github</span>.<span class="params">coxxx</span>&#x27;, <span class="params">port</span>=443)</span>: Max retries exceeded <span class="keyword">with</span> url:<span class="operator"> / </span>(Caused by <span class="constructor">NewConnectionError(&#x27;&lt;<span class="params">urllib3</span>.<span class="params">connection</span>.VerifiedHTTPSConnection <span class="params">object</span> <span class="params">at</span> 0x7fd5b5d33100&gt;: <span class="params">requests</span>.<span class="params">exceptions</span>.SSLError: [Errno 1] <span class="params">_ssl</span>.<span class="params">c</span>:503: <span class="params">error</span>:14090086:SSL <span class="params">routines</span>:SSL3_GET_SERVER_CERTIFICATE:<span class="params">certificate</span> <span class="params">verify</span> <span class="params">failed</span>&#x27;)</span>)</span><br></pre></td></tr></table></figure><blockquote><p>可以观察到报错信息的最后部分是<code>certificate verify failed</code>。</p></blockquote><h4 id="3网络不稳定"><a class="markdownIt-Anchor" href="#3网络不稳定"></a> 3.网络不稳定</h4><p>你所发送请求的主机与目标服务器之间的通信路线不稳定（如跨国）或两者之间其中之一的带宽受限导致的网络不稳定现象所致：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: requests.exceptions.ConnectionError: <span class="constructor">HTTPSConnectionPool(<span class="params">host</span>=’<span class="params">www</span>.<span class="params">github</span>.<span class="params">com</span>’, <span class="params">port</span>=443)</span>: Max retries exceeded <span class="keyword">with</span> url:<span class="operator"> / </span>(Caused by <span class="constructor">NewConnectionError(‘&lt;<span class="params">urllib3</span>.<span class="params">connection</span>.VerifiedHTTPSConnection <span class="params">object</span> <span class="params">at</span> 0x7f7f5fadb100&gt;: Failed <span class="params">to</span> <span class="params">establish</span> <span class="params">a</span> <span class="params">new</span> <span class="params">connection</span>: [Errno -3] Temporary <span class="params">failure</span> <span class="params">in</span> <span class="params">name</span> <span class="params">resolution</span>’)</span>)</span><br></pre></td></tr></table></figure><blockquote><p>可以观察到报错信息的最后部分是<code>Temporary failure in name resolution</code>。</p></blockquote><h4 id="4发送太多请求服务器过载"><a class="markdownIt-Anchor" href="#4发送太多请求服务器过载"></a> 4.发送太多请求/服务器过载</h4><p>当如此快地发出如此多的请求时，某些网站会阻止连接。与此相关的另一个问题是当服务器过载时——同时管理大量连接。或者你的IP已经被目标服务器加入了黑名单（被封锁IP）。在这种情况下，<code>requests.get()</code> 会抛出如下错误：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.exceptions.ConnectionError: <span class="constructor">HTTPConnectionPool(<span class="params">host</span>=&#x27;<span class="params">www</span>.<span class="params">github</span>.<span class="params">com</span>&#x27;, <span class="params">port</span>=80)</span>: Max retries exceeded <span class="keyword">with</span> url:<span class="operator"> / </span>(Caused by <span class="constructor">NewConnectionError(&#x27;&lt;<span class="params">urllib3</span>.<span class="params">connection</span>.HTTPConnection <span class="params">object</span> <span class="params">at</span> 0x0000008EC69AAA90&gt;: Failed <span class="params">to</span> <span class="params">establish</span> <span class="params">a</span> <span class="params">new</span> <span class="params">connection</span>: [Errno 11001] <span class="params">getaddrinfo</span> <span class="params">failed</span>&#x27;)</span>)</span><br></pre></td></tr></table></figure><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="constructor">HTTPConnectionPool(<span class="params">host</span>=&#x27;<span class="params">www</span>.<span class="params">github</span>.<span class="params">com</span>&#x27;, <span class="params">port</span>=80)</span>: Max retries exceeded <span class="keyword">with</span> url: /api/v2/oauth (Caused by <span class="constructor">NewConnectionError(&#x27;&lt;<span class="params">urllib3</span>.<span class="params">connection</span>.HTTPConnection <span class="params">object</span> <span class="params">at</span> 0x7fac5953ab70&gt;: Failed <span class="params">to</span> <span class="params">establish</span> <span class="params">a</span> <span class="params">new</span> <span class="params">connection</span>: [Errno 110] Connection <span class="params">timed</span> <span class="params">out</span>&#x27;)</span>)</span><br></pre></td></tr></table></figure><hr /><h3 id="二-应对方案"><a class="markdownIt-Anchor" href="#二-应对方案"></a> 二、应对方案</h3><hr /><h4 id="1方案一仔细检查-url"><a class="markdownIt-Anchor" href="#1方案一仔细检查-url"></a> 1.方案一：仔细检查 URL</h4><p>确保您拥有正确且有效的 URL。考虑前面提到的有效 URL：“ <a href="https://www.github.com">https://www.github.com</a> ”。“Max retries exceeded with url”错误主要发生在对<code>www</code> 和顶级域名（例如 <code>.com</code>）进行错误编辑时。</p><blockquote><p>当方案/协议 (https) 被错误编辑时会出现另一个错误：requests.exceptions.InvalidSchema。如果二级域（在我们的例子中是“github”）被错误编辑，我们将被引导到一个完全不同的网站，如果该网站不存在，我们会收到 404 响应。</p></blockquote><blockquote><p>导致“超过 url 的最大重试次数”的其他错误 URL 是“<a href="http://wwt.github.com">wwt.github.com</a>”和“<a href="https://www.github.com">https://www.github.com</a>”（.com 之后的空格）。</p></blockquote><hr /><h4 id="2方案二解决sslerror"><a class="markdownIt-Anchor" href="#2方案二解决sslerror"></a> 2.方案二：解决SSLError</h4><p>如前所述，该错误是由不受信任的 SSL 证书引起的。最快的解决方法是<strong>在<code>requests.get()</code>上设置属性 <code>verify=False</code></strong>。这告诉 requests 在不验证 SSL 证书的情况下发送请求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(<span class="string">&#x27;https://www.github.com&#x27;</span>, verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><strong>请注意</strong>，证书不会被验证；因此，您的应用程序将面临中间人攻击等安全威胁。对于在生产级别使用的脚本，最好避免使用此方法。</p><hr /><h4 id="3方案三解决网络不稳定的问题"><a class="markdownIt-Anchor" href="#3方案三解决网络不稳定的问题"></a> 3.方案三：解决网络不稳定的问题</h4><p>此解决方案适用于间歇性连接中断的情况。在这些情况下，我们希望请求能够在抛出错误之前对请求进行多次尝试。对于这种情况，我们可以使用两种解决方案：</p><blockquote><ul><li>在 <code>requests.get()</code> 中发出超时参数。</li><li>在出现与连接相关的错误时重试连接。</li></ul></blockquote><hr /><h5 id="方案a"><a class="markdownIt-Anchor" href="#方案a"></a> 方案A</h5><blockquote><p>在 <code>requests.get()</code> 中发出超时参数。</p></blockquote><p>1.如果服务器过载，我们可以使用超时来等待更长时间的响应。这将增加请求成功完成的机会。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">url = <span class="string">&#x27;https://www.github.com&#x27;</span></span><br><span class="line">res = requests.get(url,  timeout=<span class="number">7</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><p><em>上面的代码将等待 7 秒，以便请求包连接到站点并读取源代码。</em></p><p>2.你可以将超时作为双元素元组传递，其中第一个元素是连接超时（与服务器建立连接的时间），第二个值是读取超时（允许客户端从服务器读取数据的时间）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get(<span class="string">&#x27;https://api.github.com&#x27;</span>, timeout=(<span class="number">3</span>, <span class="number">7</span>))</span><br></pre></td></tr></table></figure><p><em>使用以上线路时，必须在3秒内建立连接，7秒内读取数据；否则，请求会引发超时错误。</em></p><hr /><h5 id="方案b"><a class="markdownIt-Anchor" href="#方案b"></a> 方案B</h5><blockquote><p>在出现连接相关错误时重试连接.</p></blockquote><p>这些请求使用urllib3 中的<strong>重试实用程序</strong> ( <code>urllib3.util.Retry</code> ) 来重试连接。我们将使用以下代码发送请求：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.adapters <span class="keyword">import</span> HTTPAdapter, Retry</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_request</span>(<span class="params">url,</span></span><br><span class="line"><span class="params">    n_retries=<span class="number">4</span>,</span></span><br><span class="line"><span class="params">    backoff_factor=<span class="number">0.9</span>,</span></span><br><span class="line"><span class="params">    status_codes=[<span class="number">504</span>, <span class="number">503</span>, <span class="number">502</span>, <span class="number">500</span>, <span class="number">429</span>]</span>):</span><br><span class="line">  </span><br><span class="line">    sess = requests.Session()</span><br><span class="line">    retries = Retry(connect=n_retries, backoff_factor=backoff_factor, status_forcelist=status_codes)</span><br><span class="line">    sess.mount(<span class="string">&quot;https://&quot;</span>, HTTPAdapter(max_retries=retries))</span><br><span class="line">    sess.mount(<span class="string">&quot;http://&quot;</span>, HTTPAdapter(max_retries=retries))</span><br><span class="line">    res = sess.get(url)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure><p>我们在<code>urllib3.util.Retry</code>类中使用了以下参数：</p><ul><li><strong>connect</strong> – 与连接相关的尝试次数。默认情况下， <code>send_request()</code>将进行 4 次尝试加 1 次（立即发生的原始请求）。</li><li><strong>backoff_factor</strong> – 确定重试之间的延迟。休眠时间使用公式<code>&#123;backoff_factor&#125; * (2 ^ (&#123;retry_number&#125; – 1))</code>计算。我们将在调用该函数时处理此参数的示例。</li><li><strong>status_forcelist</strong> – 仅重试导致 <code>504</code>、<code>503</code>、<code>502</code>、<code>500</code> 和 <code>429</code> 状态代码的所有连接。</li></ul><blockquote><p>现在让我们调用我们的函数并计时执行。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始一个计时器</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 请求Github API</span></span><br><span class="line">url = <span class="string">&quot;https://api.github.com/users&quot;</span></span><br><span class="line">res = send_request(url)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 打印返回状态码</span></span><br><span class="line"><span class="built_in">print</span>(res.status_code)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 结束计时器</span></span><br><span class="line">end_time = time.time()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 计算运行时长</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Run time: &quot;</span>, end_time-start_time)</span><br></pre></td></tr></table></figure><p><strong>输出：</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">200</span></span><br><span class="line"><span class="attribute">Run</span> time:  <span class="number">0</span>.<span class="number">8597214221954346</span></span><br></pre></td></tr></table></figure><p><em>连接已成功完成（状态 <code>200</code>），耗时 0.86 秒。要查看退避的实现，让我们尝试向不存在的服务器发送请求，在异常发生时捕获异常并计算执行时间。</em></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 启动执行定时器</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    url = <span class="string">&quot;http://localhost/6000&quot;</span></span><br><span class="line">    <span class="comment"># 调用send_request()方法向url发送请求</span></span><br><span class="line">    <span class="comment"># 这永远不会成功，因为没有服务器在运行</span></span><br><span class="line">    <span class="comment"># 在端口 6000 上。</span></span><br><span class="line">    response = send_request(url)</span><br><span class="line">    <span class="built_in">print</span>(response.status_code)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="comment"># 捕获任何异常 - 执行将在这里结束，因为</span></span><br><span class="line">    <span class="comment"># 请求无法连接到 http://localhost/6000</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error Name: &quot;</span>, e.__class__.__name__)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Error Message: &quot;</span>, e)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    <span class="comment"># 选择结束时间</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    <span class="comment"># 计算执行所花费的时间</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Run time: &quot;</span>, end_time-start_time)</span><br></pre></td></tr></table></figure><p><strong>输出：</strong></p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Error </span>Name:  ConnectionError</span><br><span class="line"><span class="keyword">Error </span>Message:  HTTPConnectionPool(host=&#x27;localhost&#x27;, port=80): Max retries exceeded with url: /6000 (Caused by NewConnectionError(&#x27;&lt;urllib3.connection.HTTPConnection object at 0x7f06a5862a00&gt;: Failed to establish a new connection: [Errno 111] Connection refused&#x27;))</span><br><span class="line">Run time:  12.61784315109253</span><br></pre></td></tr></table></figure><p>在 <code>backoff_factor=0.9</code> 的 4 次重试（加上 1 个原始请求）之后，执行时间为 12.6 秒。让我们使用之前看到的公式来计算睡眠时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sleeping_time = &#123;backoff_factor&#125; * (<span class="number">2</span> ^ (&#123;retry_number&#125; – <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>总共有5个请求</p><ul><li>第一个请求（立即发出）——睡眠<code>0 </code>秒，</li><li>第一次重试（也是在第一次请求失败后立即发送）——<code>0</code>秒休眠，</li><li>第二次重试-&gt; <code>0.9*(2^(2-1)) = 0.9*2 = 1.8</code> 秒睡眠，</li><li>第三次重试 -&gt; <code>0.9*(2^(3-1)) = 0.9*4 = 3.6</code> 秒的休眠时间，以及，</li><li>第四次重试 -&gt; <code>0.9*(2^(4-1)) = 0.9*8 = 7.2</code>秒。</li></ul><blockquote><p>这是<code>urllib3.util.Retry</code>实现的总共 <code>12.6</code> 秒的休眠时间。实际执行时间为<code>12.61784315109253</code>秒。未说明的 <code>0.01784315109253</code> 差异归因于 DNC 和一般计算机电源延迟。</p></blockquote><hr /><h4 id="4方案四超时处理服务器请求"><a class="markdownIt-Anchor" href="#4方案四超时处理服务器请求"></a> 4.方案四：超时处理服务器请求</h4><p>一些网站会阻止网络爬虫。他们注意到机器人正在根据传递的标头发送请求。例如，让我们运行此代码并打开详细信息以查看幕后发生的情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> http.client</span><br><span class="line"> </span><br><span class="line"><span class="comment"># turn verbose on</span></span><br><span class="line">http.client.HTTPConnection.debuglevel = <span class="number">1</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">&#x27;https://www.github.com&#x27;</span></span><br><span class="line">res = requests.get(url=url)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><p><strong>输出(Curl)：</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">send</span>: b&#x27;GET / HTTP/<span class="number">1</span>.<span class="number">1</span>\r\nHost: www.github.com\r\nUser-Agent: python-requests/<span class="number">2</span>.<span class="number">28</span>.<span class="number">1</span>\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;</span><br><span class="line"><span class="attribute">reply</span>: &#x27;HTTP/<span class="number">1</span>.<span class="number">1</span> <span class="number">200</span> OK\r\n&#x27;</span><br></pre></td></tr></table></figure><p>在该日志中，您可以看到 <code>User-Agent</code> 是 <code>python-requests v2.28.1</code> 而不是真正的浏览器。使用此类标识，您可能会被阻止并收到“超过 url 的最大重试次数”错误。为避免这种情况，我们需要将我们的实际浏览器作为用户代理传递。您可以转到以下链接获取一些标头： <a href="http://myhttpheader.com/">http://myhttpheader.com/</a>。在该链接中，我的用户代理是“<code>Mozilla/5.0 (X11; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0</code>”。现在让我们改用该用户代理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.client</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 打开详细信息</span></span><br><span class="line">http.client.HTTPConnection.debuglevel = <span class="number">1</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"> </span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (X11; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0&#x27;</span>&#125;</span><br><span class="line">url = <span class="string">&#x27;https://www.github.com&#x27;</span></span><br><span class="line">res = requests.get(url=url,  timeout=<span class="number">5</span>, headers=headers)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure><p><strong>输出(Curl)：</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">send</span>: b&#x27;GET / HTTP/<span class="number">1</span>.<span class="number">1</span>\r\nHost: www.github.com\r\nUser-Agent: Mozilla/<span class="number">5</span>.<span class="number">0</span> (X11; Linux x86_64; rv:<span class="number">91</span>.<span class="number">0</span>) Gecko/<span class="number">20100101</span> Firefox/<span class="number">91</span>.<span class="number">0</span>\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\n\r\n&#x27;</span><br><span class="line"><span class="attribute">reply</span>: &#x27;HTTP/<span class="number">1</span>.<span class="number">1</span> <span class="number">200</span> OK\r\n&#x27;</span><br></pre></td></tr></table></figure><p><strong>重要：</strong></p><blockquote><p>针对被高级反爬及被封禁IP的解决方法策略有所不同。</p></blockquote><p>1.被高级反爬后的处理：<br />例如像国内rs这样的中高级动态反爬技术，其原理是检测用户浏览器环境是否为真实的用户环境。</p><blockquote><p>针对此类问题需要采用更加高级的手段进行沙盒实验及补环境。</p></blockquote><p>2.所使用的设备被目标主机封禁IP。</p><blockquote><p>针对此类问题，可以使用IP代理池，每次请求都随机更换IP来避免被封禁；其次，需要降低请求的速率。</p></blockquote><p><strong>注意：请遵守所在国家或地区的法律法规。</strong></p><hr /><p>本文属于作者自主知识产权的原创文章，如须引用、转载，请注明来源：</p><blockquote><p>版权声明：本文为博主「<a href="https://blog.inetgeek.cn/">Colyn</a>」的原创文章，遵循<a href="https://creativecommons.org/licenses/by-sa/4.0/">CC 4.0 BY-SA</a>版权协议，转载请附上原文出处链接及本声明。<br />原文链接：<a href="http://blog.inetgeek.cn/">https://blog.inetgeek.cn/</a></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;ul class=&quot;markdownIt-TOC&quot;&gt;
&lt;li&gt;&lt;a href=&quot;#%E4%B8%80-%E6%99%AE%E9%81%8D%E6%96%B9%E6%A1%88&quot;&gt;一、普遍方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#%E7%BB%86%E8%87%B</summary>
      
    
    
    
    <category term="编程" scheme="https://blog.inetgeek.cn/categories/%E7%BC%96%E7%A8%8B/"/>
    
    <category term="Python" scheme="https://blog.inetgeek.cn/categories/Python/"/>
    
    
    <category term="Python" scheme="https://blog.inetgeek.cn/tags/Python/"/>
    
    <category term="Spider" scheme="https://blog.inetgeek.cn/tags/Spider/"/>
    
  </entry>
  
</feed>
